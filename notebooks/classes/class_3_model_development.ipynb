{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56969d37",
   "metadata": {},
   "source": [
    "![title](../assets/problem.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be7e877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from typing import Dict, List, Union, Any\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff6e1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 5000)\n",
    "pd.set_option('max_colwidth', 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407bd2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"/Users/seanariel/Desktop/la-maniee/data/mlops\"\n",
    "\n",
    "PATH_TO_SYNTHETIC_DATA = f\"{BASE_PATH}/synthetic_data_contract.csv\"\n",
    "PATH_TO_EXPLODED_FEATURES = f\"{BASE_PATH}/exploded_features.csv\"\n",
    "PATH_TO_FEATURE_STORE = f\"{BASE_PATH}/feature_store.csv\"\n",
    "PATH_TO_DEV_TRAINING_DATA = f\"{BASE_PATH}/dev_training.csv\"\n",
    "PATH_TO_DEV_TESTING_DATA = f\"{BASE_PATH}/dev_testing.csv\"\n",
    "PATH_TO_AUTOML_TRAINING_DATA = f\"{BASE_PATH}/automl_training.csv\"\n",
    "PATH_TO_PRECISION_RECALL = f\"{BASE_PATH}/precision_recall.csv\"\n",
    "PATH_TO_OPTIMAL_MODEL = f\"{BASE_PATH}/optimal_model.pickle\"\n",
    "PATH_TO_PRODUCTION_MODEL = f\"{BASE_PATH}/production_model.pickle\"\n",
    "PATH_TO_TRAINING_DATA = f\"{BASE_PATH}/training.csv\"\n",
    "PATH_TO_EXPERIMENTATION_DATA = f\"{BASE_PATH}/experimentation.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306c438f",
   "metadata": {},
   "source": [
    "# Table of Content:\n",
    "* [Overview](#first-bullet)\n",
    "* [Feature Engineering](#second-bullet)\n",
    "* [Model Development](#third-bullet)\n",
    "* [Model Training](#fourth-bullet)\n",
    "* [Model Serving](#fifth-bullet)\n",
    "* [Model Experimentation](#sixth-bullet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa06a57",
   "metadata": {},
   "source": [
    "# Model Development <a class=\"anchor\" id=\"third-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10878136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from typing import Dict, List, Union\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, accuracy_score, recall_score, precision_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506160c3",
   "metadata": {},
   "source": [
    "### Import feature store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df099132",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE = 10000\n",
    "feature_store = pd.read_csv(PATH_TO_FEATURE_STORE, nrows=SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b1eef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26aba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"p1_has_won\"\n",
    "SEGMENTS = [\"reward\", \"contract\"]\n",
    "COVARIATES = list(filter(lambda covariate: covariate not in [TARGET], feature_store.columns))\n",
    "BASE_THRESHOLD = 0.5\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058dfcd4",
   "metadata": {},
   "source": [
    "### Split the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc11642",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Make sure to set a holdout frame on the side.\n",
    "\"\"\"\n",
    "(\n",
    "    covariates_training,\n",
    "    covariates_testing,\n",
    "    target_training,\n",
    "    target_testing,\n",
    ") = ...( # split the dataset between training and testing sets\n",
    "    feature_store[COVARIATES],\n",
    "    feature_store[TARGET],\n",
    "    ..., # keep 25% of samples in the test set\n",
    "    random_state=RANDOM_STATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15971c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(covariates_training.shape)\n",
    "print(covariates_testing.shape)\n",
    "print(target_training.shape)\n",
    "print(target_testing.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3b4de2",
   "metadata": {},
   "source": [
    "### Preserve the segments and ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecab716",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_covariates_training = covariates_training[SEGMENTS]\n",
    "covariates_training = covariates_training.drop(SEGMENTS, axis=1)\n",
    "\n",
    "segment_covariates_testing = covariates_testing[SEGMENTS]\n",
    "covariates_testing = covariates_testing.drop(SEGMENTS, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc45af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "COVARIATES = list(filter(lambda covariate: covariate not in ([TARGET] + SEGMENTS), feature_store.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84745cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(COVARIATES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09031e9d",
   "metadata": {},
   "source": [
    "### Get a first feeling of Bias vs Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbb1bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_hypers = {\n",
    "    \"n_estimators\": 5000,\n",
    "}\n",
    "\n",
    "def generate_scoring(model, training_cov, training_tar, testing_cov, testing_tar) -> Dict[str, float]:\n",
    "    model ... ( # train the model on the training set\n",
    "        training_cov[COVARIATES].values, training_tar.values.ravel()\n",
    "    )\n",
    "    predictions: np.array = model ... (testing_cov[COVARIATES])[:, 1] # predict the new samples with the trained model\n",
    "    predictions: np.array = np.where(predictions > BASE_THRESHOLD, 1, 0)\n",
    "    return {\n",
    "        \"accuracy_score\": ... (testing_tar, predictions), # generate the accuracy score\n",
    "        \"recall_score\": ... (testing_tar, predictions), # generate the recall score\n",
    "        \"precision_score\": ... (testing_tar, predictions), # generate the prediction score\n",
    "    }\n",
    "\n",
    "pipeline = {\n",
    "    \"BaggingClassifier\": BaggingClassifier(\n",
    "        **{**base_hypers, **{\"n_jobs\": -1}}\n",
    "    ),\n",
    "    \"GradientBoostingClassifier\": GradientBoostingClassifier(\n",
    "        **{**base_hypers, **{\"max_depth\": 5, \"min_samples_split\": 5, \"min_samples_leaf\": 5}}\n",
    "    ),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(\n",
    "        **{**base_hypers, **{\"max_depth\": 5, \"min_samples_split\": 5, \"min_samples_leaf\": 5, \"n_jobs\": -1}}\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "class ModelEvaluation:\n",
    "    \n",
    "    def __init__(self, name, model, metrics):\n",
    "        self.name: str = name\n",
    "        self.model: Any = model\n",
    "        self.metrics: Dict[str, float] = metrics\n",
    "        \n",
    "    @property\n",
    "    def accuracy_score(self):\n",
    "        return # look up inside the metrics Dict and get the accuracy score\n",
    "    \n",
    "    @property\n",
    "    def recall_score(self):\n",
    "        return # look up inside the metrics Dict and get the recall score\n",
    "    \n",
    "    @property\n",
    "    def precision_score(self):\n",
    "        return # look up inside the metrics Dict and get the precision score\n",
    "\n",
    "\n",
    "metric_accumulators = []\n",
    "for name, model in pipeline.items():\n",
    "    metrics = ... ( # generate the scoring \n",
    "        model, covariates_training, target_training, covariates_testing, target_testing\n",
    "    )\n",
    "    metric_accumulators.append(\n",
    "        ... (name, model, metrics) # instantiate a model evaluation object \n",
    "    )\n",
    "    print(name, \" - \\n\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce065d2a",
   "metadata": {},
   "source": [
    "### Train the optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38f3456",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ... () # instantiate a new random forest classifier\n",
    "hyperparameters_grid = {\n",
    "    \"n_estimators\": [5000],\n",
    "    \"max_depth\": [5],\n",
    "    \"min_samples_split\": [5],\n",
    "    \"min_samples_leaf\": [5],\n",
    "}\n",
    "random_search = ... ( # instantiate a randomised grid search cv object\n",
    "    base_model,\n",
    "    param_distributions=hyperparameters_grid,\n",
    "    n_iter=1,\n",
    "    scoring=None,\n",
    "    n_jobs=-1,\n",
    "    cv=2,\n",
    "    verbose=1,\n",
    "    refit=False,\n",
    ")\n",
    "random_search ... ( # train the randomised grid search object\n",
    "    covariates_training[COVARIATES], target_training.values.reshape(-1, 1)\n",
    ")\n",
    "optimal_hyper_parameters, cv_results = random_search.best_params_, random_search.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346c27f4",
   "metadata": {},
   "source": [
    "### Train the optimal model on the whole training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f343623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_hyper_parameters = {\n",
    "    \"n_estimators\": 5000,\n",
    "    \"max_depth\": 5,\n",
    "    \"min_samples_split\": 5,\n",
    "    \"min_samples_leaf\": 5\n",
    "}\n",
    "base_model = RandomForestClassifier(\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "optimal_model = base_model ... (**optimal_hyper_parameters) # set the optimal HP to the base model\n",
    "optimal_model.fit(\n",
    "    covariates_training[COVARIATES].values, target_training.values.ravel()\n",
    ")\n",
    "\n",
    "with open(PATH_TO_OPTIMAL_MODEL, 'wb') as handle:\n",
    "    pickle.dump(optimal_model, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "covariates_training.to_csv(PATH_TO_DEV_TRAINING_DATA, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ef79a5",
   "metadata": {},
   "source": [
    "### Generate the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac40a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = optimal_model.predict_proba(covariates_testing[COVARIATES])[:, 1]\n",
    "covariates_testing[\"predictions\"] = predictions\n",
    "covariates_testing[\"target\"] = target_testing\n",
    "covariates_testing[\"predicted\"] = covariates_testing[\"predictions\"].apply(\n",
    "    lambda x: 1 if x > BASE_THRESHOLD else 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff53f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates_testing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da41ab9",
   "metadata": {},
   "source": [
    "### Generate the precision and recall metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfc557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_arr, recall_arr, threshold_arr = precision_recall_curve(\n",
    "    target_testing, predictions\n",
    ")\n",
    "metrics_df = pd.DataFrame(\n",
    "    {\n",
    "        \"precision\": precision_arr[1:],\n",
    "        \"recall\": recall_arr[1:],\n",
    "        \"threshold\": threshold_arr,\n",
    "    }\n",
    ")\n",
    "metrics_df[\"threshold\"] = metrics_df[\"threshold\"].apply(lambda x: round(x, 2))\n",
    "metrics_df.drop_duplicates(subset=[\"threshold\"], keep=\"first\", inplace=True)\n",
    "metrics_df.to_csv(PATH_TO_PRECISION_RECALL, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50358313",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c39318",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ROC_AUC\", roc_auc_score(target_testing, predictions))\n",
    "print(\"Accuracy\", accuracy_score(target_testing, covariates_testing.predicted))\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(metrics_df[\"recall\"].values, metrics_df[\"precision\"].values, color='purple')\n",
    "ax.set_title('Precision-Recall Curve')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlabel('Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6682b7bf",
   "metadata": {},
   "source": [
    "### Interpret the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c297b7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = optimal_model.feature_importances_\n",
    "indices = np.argsort(importances)[-15:]\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [COVARIATES[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08389194",
   "metadata": {},
   "source": [
    "### Study the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6ae4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df[metrics_df.threshold == BASE_THRESHOLD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00748655",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df[metrics_df.precision > 0.9].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bc9883",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUSINESS_THRESDHOLD = 0.65\n",
    "\n",
    "covariates_testing[\"business_predicted\"] = covariates_testing[\"predictions\"].apply(\n",
    "    lambda x: 1 if x > BUSINESS_THRESDHOLD else 0\n",
    ")\n",
    "covariates_testing = pd.concat([covariates_testing, segment_covariates_testing], axis=1)\n",
    "covariates_testing.to_csv(PATH_TO_DEV_TESTING_DATA, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60111cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = covariates_testing[covariates_testing.target != covariates_testing.predicted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85dcfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates_testing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca16a9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates_testing.contract.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6769845",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db932c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors.contract.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59d8d01",
   "metadata": {},
   "source": [
    "### [Optional] Assignment 3 - Google Cloud Engine Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0557ebd5",
   "metadata": {},
   "source": [
    "Let's head over to Google Cloud Engine to set up a larger VM.\n",
    "This will allow us to run larger development pipelines such as:\n",
    "\n",
    "- Large scale grid search (Bayesian, Random or Grid)\n",
    "- Tuning over subset of models (Boosters, Trees and NN)\n",
    "\n",
    "First, make sure to set up you <a> Google Cloud Storage </a> bucket that we will use throughout this course.\n",
    "\n",
    "Then, follow this lab to set up your <a> Google Cloud VM </a> server and launch a first E2E model development run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0990a3fc",
   "metadata": {},
   "source": [
    "### [Optional] Assignment 4 - Google AutoML (Vertex) Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cb957a",
   "metadata": {},
   "source": [
    "Let's head over to <a> Google Cloud Vertex AI </a> to launch automated training pipelines at scale.\n",
    "\n",
    "We will essentially replicate the workflow we have set up here - but most of it will be abstracted from us through this complete, no-code solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f84e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store = pd.read_csv(PATH_TO_FEATURE_STORE)\n",
    "feature_store[COVARIATES + [TARGET]].to_csv(PATH_TO_AUTOML_TRAINING_DATA, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63c33a3",
   "metadata": {},
   "source": [
    "#### Credit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd506e2",
   "metadata": {},
   "source": [
    "Note:\n",
    "This content has been developed by Sean Ariel for educational purposes. \n",
    "It is a practical training that cannot be copied, reproduced, distributed without the explicit consent from the author. © Sean Ariel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b274894b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
